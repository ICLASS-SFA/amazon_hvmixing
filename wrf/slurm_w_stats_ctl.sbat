#!/bin/bash
#SBATCH -A m1657
#SBATCH -J ctl
#SBATCH -t 00:30:00
#SBATCH -q debug
#SBATCH -C cpu
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=32
#SBATCH --exclusive
#SBATCH --output=log_w_stats_ctl_dask.log
#SBATCH --mail-type=END
#SBATCH --mail-user=zhe.feng@pnnl.gov

date
source activate /global/common/software/m1867/python/py310

# Increase limit on number of open files
ulimit -n 32000
export DASK_DISTRIBUTED__COMM__TIMEOUTS__CONNECT=360s
export DASK_DISTRIBUTED__COMM__TIMEOUTS__TCP=360s

# Generate a scheduler filename with a random string
random_str=`echo $RANDOM | md5sum | head -c 10`
scheduler_file=$SCRATCH/scheduler_${random_str}.json

# Start Dask scheduler manually
dask-scheduler --scheduler-file=$scheduler_file &

## Start dask cluster
#srun -u dask-mpi \
#--scheduler-file=$scheduler_file \
#--nthreads=1 \
#--memory-limit='auto' \
#--worker-class distributed.Worker \
#--local-directory=/tmp &
#
#sleep 5

srun -N 2 --ntasks-per-node=32 dask worker \
--scheduler-file=$scheduler_file \
--memory-limit='16GB' \
--worker-class distributed.Worker \
--local-directory=/tmp &

sleep 10

cd /global/homes/f/feng045/program/iclass/re2/amazon_hvmixing/wrf

# python calc_wrf_mcs_w_stats.py config_w_ctl.yml

python calc_wrf_mcs_w_stats.py config_w_ctl.yml $scheduler_file

# python calc_wrf_mcs_w_stats_from_wrfout.py config_w_ctl.yml
date
